{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23db3251-84af-4e5b-aca7-be1cc8184d1d",
   "metadata": {},
   "source": [
    "# Speed comparison of CPU vs. GPU on XGBoost with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f702bfe-d21e-4052-8130-b33d800d3c7b",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7057e12-b1ea-4fa1-810d-fa5b9bface81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1395b8-1802-4b5a-b5e5-6ffb9a11cd0e",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88552049-b4f5-49bc-b899-f9a3afabd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ebf452-5537-4e3a-8529-f8aa96a690d4",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0324c7fa-319a-4aa9-816a-89e41d1bdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b21a9c-267a-4876-b5c1-280e4b1c0c13",
   "metadata": {},
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "120ae8cf-c6b4-4da0-905f-d524e9664a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eunchong/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution fit time: 19 s\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_dist = {\n",
    "    'objective': 'multi:softmax', \n",
    "    'n_estimators': 2\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier(**param_dist)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "        eval_metric='logloss',\n",
    "        verbose=True)\n",
    "\n",
    "print('Execution fit time: %i s' % int(time.time()-start_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7054ab-f03c-4cc5-80c4-caf8826106d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1318    0    6    4    6    8    9    3   22    5]\n",
      " [   0 1517   17    9    4    4    8    5    9    2]\n",
      " [  29   15 1242   24   12    6    8   12   45    5]\n",
      " [  10   15   48 1225    8   42    9   17   35   19]\n",
      " [   4    6    7    7 1214   15    9   12   23   68]\n",
      " [  21    9    5   74   10 1021   32    8   44   39]\n",
      " [  18    3    5    5   26   27 1268    0   22    1]\n",
      " [   2   10   25   15   19    5    0 1288   19   75]\n",
      " [   8   19   22   33   17   22    6    9 1195   34]\n",
      " [   5    5    5   26   37   16    0   42   13 1243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1381\n",
      "           1       0.95      0.96      0.96      1575\n",
      "           2       0.90      0.89      0.89      1398\n",
      "           3       0.86      0.86      0.86      1428\n",
      "           4       0.90      0.89      0.89      1365\n",
      "           5       0.88      0.81      0.84      1263\n",
      "           6       0.94      0.92      0.93      1375\n",
      "           7       0.92      0.88      0.90      1458\n",
      "           8       0.84      0.88      0.86      1365\n",
      "           9       0.83      0.89      0.86      1392\n",
      "\n",
      "    accuracy                           0.90     14000\n",
      "   macro avg       0.89      0.89      0.89     14000\n",
      "weighted avg       0.90      0.90      0.90     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cc75c-b4fa-493f-a550-50a28d8306cd",
   "metadata": {},
   "source": [
    "## 5. XGBoost with Cuda (not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd898afb-7b09-43e2-9114-e3337a33b6bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[20:22:37] ../src/tree/updater_gpu_hist.cu:793: Exception in gpu_hist: NCCL failure :unhandled system error ../src/common/device_helpers.cu(71)\n\nStack trace:\n  [bt] (0) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x9133f) [0x7fb51a8fc33f]\n  [bt] (1) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x4e9a88) [0x7fb51ad54a88]\n  [bt] (2) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x18c862) [0x7fb51a9f7862]\n  [bt] (3) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x18ead8) [0x7fb51a9f9ad8]\n  [bt] (4) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1b9b93) [0x7fb51aa24b93]\n  [bt] (5) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x50) [0x7fb51a8ebed0]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7fb5ff00cff5]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7fb5ff00c40a]\n  [bt] (8) /usr/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x5b6) [0x7fb5ff025316]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_400/3340018636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m clf.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logloss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         verbose=True)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         )\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [20:22:37] ../src/tree/updater_gpu_hist.cu:793: Exception in gpu_hist: NCCL failure :unhandled system error ../src/common/device_helpers.cu(71)\n\nStack trace:\n  [bt] (0) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x9133f) [0x7fb51a8fc33f]\n  [bt] (1) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x4e9a88) [0x7fb51ad54a88]\n  [bt] (2) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x18c862) [0x7fb51a9f7862]\n  [bt] (3) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x18ead8) [0x7fb51a9f9ad8]\n  [bt] (4) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1b9b93) [0x7fb51aa24b93]\n  [bt] (5) /home/eunchong/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x50) [0x7fb51a8ebed0]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7fb5ff00cff5]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7fb5ff00c40a]\n  [bt] (8) /usr/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x5b6) [0x7fb5ff025316]\n\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_dist = {\n",
    "    'objective': 'multi:softmax', \n",
    "    'n_estimators': 2,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'gpu_id': 0\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier(**param_dist)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "        eval_metric='logloss',\n",
    "        verbose=True)\n",
    "\n",
    "print('Execution fit time: %i s' % int(time.time()-start_time) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
